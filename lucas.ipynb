{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66f26caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lucas.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "010e42bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"$%&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz~‘’“”\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1edf7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7a06275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([211199]) <built-in method type of Tensor object at 0x000001F36C21B390>\n",
      "tensor([ 0, 36, 55, 70, 70, 79,  2, 36, 55, 66, 66, 69, 77, 59, 59, 68,  3,  2,\n",
      "        37,  2, 57, 55, 68, 83, 74,  2, 56, 59, 66, 63, 59, 76, 59,  2, 63, 74,\n",
      "        83, 73,  2, 42, 69, 76, 59, 67, 56, 59, 72,  2, 55, 66, 72, 59, 55, 58,\n",
      "        79,  3,  2, 48, 62, 63, 73,  2, 79, 59, 55, 72,  2, 63, 73,  2, 67, 79,\n",
      "         2, 60, 63, 72, 73, 74,  2, 79, 59, 55, 72,  2, 68, 69, 74,  2, 61, 69,\n",
      "        63, 68, 61,  2, 74, 72, 63, 57, 65, 13, 69, 72, 13, 74, 72, 59, 55, 74,\n",
      "        63, 68, 61, 12,  2, 77, 62, 63, 57, 62,  2, 73, 63, 61, 68, 63, 60, 63,\n",
      "        57, 55, 68, 74, 66, 79,  2, 72, 59, 58, 75, 57, 59, 58,  2, 67, 79,  2,\n",
      "        63, 68, 57, 69, 67, 59,  2, 63, 68,  2, 74, 59, 72, 67, 73,  2, 69, 60,\n",
      "         2, 57, 62, 69, 57, 69, 66, 55, 74, 59,  2, 55, 68, 58,  2, 69, 74, 62,\n",
      "        59, 72,  2, 57, 55, 68, 58, 63, 59, 73, 14,  2, 36, 69, 77, 59, 76, 59,\n",
      "        72, 12,  2, 37,  2, 73, 74, 63, 66, 66,  2, 67, 55, 68, 55, 61, 59, 58,\n",
      "         2, 74, 69,  2, 61, 59, 74,  2, 73, 69, 67, 59,  2, 57, 55, 68, 58, 79,\n",
      "         2, 60, 72, 69, 67,  2, 74, 62, 59,  2, 31, 62, 63, 68, 59, 73, 59,  2,\n",
      "        73, 57, 62, 69, 69, 66,  2, 55, 68, 58,  2, 67, 79,  2, 68, 59, 63, 61,\n",
      "        62, 56, 69, 72, 73, 14,  2, 37, 74,  2, 73, 69, 75, 68, 58, 73,  2, 66,\n",
      "        63, 65, 59,  2, 79, 69, 75, 83, 76, 59,  2, 56, 59, 59, 68,  2, 70, 72,\n",
      "        59, 74, 74, 79,  2, 56, 75, 73, 79, 12,  2, 77, 63, 74, 62,  2, 79, 69,\n",
      "        75, 72,  2, 74, 72, 63, 70, 73,  2, 55, 68, 58,  2, 76, 69, 66, 75, 68,\n",
      "        74, 59, 59, 72, 63, 68, 61,  2, 55, 57, 74, 63, 76, 63, 74, 63, 59, 73,\n",
      "         3,  2, 48, 62, 63, 73,  2, 70, 55, 73, 74,  2, 77, 59, 59, 65,  2, 77,\n",
      "        55, 73,  2, 70, 72, 69, 56, 55, 56, 66, 79,  2, 69, 68, 59,  2, 69, 60,\n",
      "         2, 67, 79,  2, 56, 75, 73, 63, 59, 73, 74,  2, 73, 69,  2, 60, 55, 72,\n",
      "        12,  2, 56, 59, 57, 55, 75, 73, 59,  2, 74, 62, 59,  2, 71, 75, 55, 72,\n",
      "        74, 59, 72,  2, 63, 73,  2, 59, 68, 58, 63, 68, 61, 14,  2, 48, 62, 59,\n",
      "        72, 59,  2, 77, 59, 72, 59,  2, 55,  2, 66, 69, 74,  2, 69, 60,  2, 74,\n",
      "        59, 73, 74, 73, 12,  2, 73, 69,  2, 74, 62, 55, 74,  2, 74, 59, 55, 57,\n",
      "        62, 59, 72, 73,  2, 57, 69, 75, 66, 58,  2, 61, 59, 74,  2, 60, 63, 68,\n",
      "        55, 66,  2, 61, 72, 55, 58, 59, 73,  2, 63, 68,  2, 69, 68,  2, 74, 63,\n",
      "        67, 59, 14,  2, 48, 62, 59, 72, 59,  2, 77, 55, 73,  2, 69, 68, 59,  2,\n",
      "        57, 69, 67, 70, 75, 74, 59, 72,  2, 73, 57, 63, 59, 68, 57, 59,  2, 73,\n",
      "        75, 67, 67, 55, 74, 63, 76, 59,  2, 74, 59, 73, 74,  2, 74, 62, 55, 74,\n",
      "         2, 62, 55, 58,  2, 55,  2, 57, 59, 72, 74, 55, 63, 68,  2, 70, 55, 74,\n",
      "        74, 59, 72, 68,  2, 74, 62, 55, 74,  2, 73, 69, 67, 59,  2, 70, 59, 69,\n",
      "        70, 66, 59,  2,  9, 68, 69, 74,  2, 63, 68, 57, 66, 75, 58, 63, 68, 61,\n",
      "         2, 67, 59, 10,  2, 68, 69, 74, 63, 57, 59, 58, 26,  2, 55, 66, 66,  2,\n",
      "        74, 62, 59,  2, 57, 69, 72, 72, 59, 57, 74,  2, 55, 68, 73, 77, 59, 72,\n",
      "        73,  2, 77, 59, 72, 59,  2, 74, 62, 59,  2, 60, 63, 72, 73, 74,  2, 57,\n",
      "        62, 69, 63, 57, 59, 14,  2, 48, 62, 59,  2, 74, 59, 55, 57, 62, 59, 72,\n",
      "         2, 60, 69, 72, 61, 69, 74,  2, 74, 69,  2, 73, 62, 75, 60, 60, 66, 59,\n",
      "         2, 74, 62, 59,  2, 55, 68, 73, 77, 59, 72, 73,  2,  9, 74, 62, 63, 73,\n",
      "         2, 77, 55, 73,  2, 55, 68,  2, 69, 68, 66, 63, 68, 59,  2, 67, 75, 66,\n",
      "        74, 63, 70, 66, 59,  2, 57, 62, 69, 63, 57, 59,  2, 74, 59, 73, 74, 10,\n",
      "        12,  2, 55, 68, 58,  2, 73, 69,  2, 55, 60, 74, 59, 72,  2, 68, 69, 74,\n",
      "        63, 57, 63, 68, 61,  2, 74, 62, 63, 73,  2, 74, 72, 59, 68, 58, 12,  2,\n",
      "        67, 55, 68, 79,  2, 70, 59, 69, 70, 66, 59,  2, 67, 55, 68, 55, 61, 59,\n",
      "        58,  2, 74, 69,  2, 61, 59, 74,  2, 17, 16, 16,  6, 14,  2, 48, 62, 59,\n",
      "         2, 61, 69, 69, 58,  2, 74, 62, 63, 68, 61,  2, 63, 73,  2, 74, 62, 55,\n",
      "        74,  2, 77, 59,  2, 58, 69, 68, 83, 74,  2, 62, 55, 76, 59,  2, 73, 57,\n",
      "        62, 69, 69, 66,  2, 68, 59, 78, 74,  2, 48, 62, 75, 72, 73, 58, 55, 79,\n",
      "        12,  2, 77, 62, 59, 68,  2, 74, 59, 55, 57, 62, 59, 72, 73,  2, 77, 63,\n",
      "        66, 66,  2, 56, 59,  2, 61, 72, 55, 58, 63, 68, 61,  2, 69, 75, 72,  2,\n",
      "        77, 69, 72, 65, 14,  2,  1, 37,  2, 62, 55, 76, 59,  2, 29, 83, 73,  2,\n",
      "        63, 68,  2, 55, 66, 66,  2, 67, 79,  2, 57, 66, 55, 73, 73, 59, 73,  2,\n",
      "        57, 75, 72, 72, 59, 68, 74, 66, 79,  2, 59, 78, 57, 59, 70, 74,  2, 47,\n",
      "        70, 55, 68, 63, 73, 62,  2, 57, 66, 55])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ef57ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = (int)(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "265bd985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 36, 55, 70, 70, 79,  2, 36, 55])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8390dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56, 59,  2, 55, 56, 66, 59,  2],\n",
      "        [74,  2, 74, 62, 63, 68, 65,  2],\n",
      "        [69, 70, 70, 63, 68, 61,  2, 63],\n",
      "        [73, 69,  2, 60, 55, 72,  2, 55]])\n",
      "tensor([[59,  2, 55, 56, 66, 59,  2, 74],\n",
      "        [ 2, 74, 62, 63, 68, 65,  2, 77],\n",
      "        [70, 70, 63, 68, 61,  2, 63, 68],\n",
      "        [69,  2, 60, 55, 72,  2, 55, 77]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # finds 4 random starting indices for getting blocks\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # gets a stack of the 4 blocks of 8 values\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # gets the next value (which is what we're trying to predict)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0394139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 86])\n",
      "tensor(4.9079, grad_fn=<NllLossBackward0>)\n",
      "\tF0IBrNR~zu\"H;goI\t7ufMOi%0w’w\n",
      "rpdoJNpf“uS5\tZ5%sjWABSAwpsJ“’e “\n",
      "gt9507K;~9k5XN.M(ir’?T&Il”9AMAHY,PL”AT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F \n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# bigram is a pair of consecutive words in a sequence\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        logits = self.token_embedding_table(inputs) # (Batch, Time, Channel)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(inputs)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            inputs_next = torch.multinomial(probs, num_samples=1) # (B, 1) as there is one prediction for what comes next\n",
    "            inputs = torch.cat((inputs, inputs_next), dim=1)\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "m = BigramLanguageModel(vocab)\n",
    "logits, loss = m(xb, yb) # passing inputs and targets\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "inputs = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(inputs, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3400cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3578c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "994124b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.zeros((1, 1), dtype=torch.long)\n",
    "# print(decode(m.generate(inputs, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4123d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C)) # bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9137b23c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m wei \u001b[38;5;241m=\u001b[39m wei\u001b[38;5;241m.\u001b[39mmasked_fill(tril \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     16\u001b[0m wei \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(wei, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m v \u001b[38;5;241m=\u001b[39m value(x)\n\u001b[0;32m     19\u001b[0m out \u001b[38;5;241m=\u001b[39m wei \u001b[38;5;241m@\u001b[39m v\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#out = wei @ x\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "#a single head of self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "print(wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ffa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\n\\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\\nprint(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803d50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9487)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "\n",
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda17f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
